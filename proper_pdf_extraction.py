#!/usr/bin/env python3
"""
PROPER PDF EXTRACTION - Page by Page Analysis
Extracts data by analyzing each PDF page structure to match location numbers correctly
"""

import PyPDF2
import pandas as pd
import re
import json
import os
from datetime import datetime

def analyze_pdf_page_structure():
    """Analyze PDF page by page to understand the real structure"""
    
    print("=" * 80)
    print("ğŸ”¬ PROPER PDF EXTRACTION - Page by Page Analysis")
    print("=" * 80)
    
    pdf_file = r"C:\Election-2025\motobus .pdf"
    
    if not os.path.exists(pdf_file):
        print(f"âŒ PDF file not found: {pdf_file}")
        return False
    
    print(f"ğŸ“„ Analyzing PDF structure page by page...")
    
    try:
        with open(pdf_file, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_pages = len(pdf_reader.pages)
            print(f"ğŸ“Š Total pages: {total_pages}")
            
            locations = []
            
            # Analyze each page to find location headers and numbers
            for page_num in range(min(50, total_pages)):  # Analyze first 50 pages
                page = pdf_reader.pages[page_num]
                text = page.extract_text()
                
                if page_num % 10 == 0:
                    print(f"   ğŸ“„ Processing page {page_num + 1}...")
                
                lines = text.split('\n')
                
                # Look for location number patterns
                location_number = None
                school_name = None
                address = None
                
                for i, line in enumerate(lines):
                    line = line.strip()
                    
                    # Pattern 1: Look for "Ø±Ù‚Ù… Ø§Ù„Ù„Ø¬Ù†Ø©" followed by a number
                    committee_match = re.search(r'Ø±Ù‚Ù…\s*Ø§Ù„Ù„Ø¬Ù†Ø©.*?(\d{1,3})', line)
                    if committee_match:
                        location_number = int(committee_match.group(1))
                    
                    # Pattern 2: Look for standalone numbers that could be location numbers
                    if re.match(r'^\d{1,3}$', line) and not location_number:
                        potential_num = int(line)
                        if 1 <= potential_num <= 1000:
                            location_number = potential_num
                    
                    # Pattern 3: Look for "Ù…Ù† 1021" pattern which indicates location number
                    from_total_match = re.search(r'(\d{1,3})\s*Ù…Ù†\s*\d+', line)
                    if from_total_match:
                        location_number = int(from_total_match.group(1))
                    
                    # Pattern 4: Look for school names
                    if 'Ù…Ø¯Ø±Ø³Ø©' in line:
                        school_match = re.search(r'Ù…Ø¯Ø±Ø³Ø©\s*([^\n\d]+)', line)
                        if school_match:
                            school_name = school_match.group(1).strip()
                    
                    # Pattern 5: Look for addresses with Ù…Ø±ÙƒØ²
                    if 'Ù…Ø±ÙƒØ²' in line and not school_name:
                        address = line
                
                # If we found a location number and school name, create a record
                if location_number and school_name:
                    
                    # Count voters on this page
                    voter_count = 0
                    for line in lines:
                        # Count Arabic names followed by numbers
                        arabic_names = re.findall(r'[\u0600-\u06FF\s]+\s+\d{4,5}', line)
                        voter_count += len(arabic_names)
                    
                    location_record = {
                        'location_id': len(locations) + 1,
                        'location_number': location_number,
                        'location_name': school_name,
                        'location_address': address if address else f"Ù…Ø±ÙƒØ² Ù…Ø·ÙˆØ¨Ø³ - ØµÙØ­Ø© {page_num + 1}",
                        'governorate': 'ÙƒÙØ± Ø§Ù„Ø´ÙŠØ®',
                        'district': 'Ù…Ø·ÙˆØ¨Ø³',
                        'page_number': page_num + 1,
                        'total_voters': max(voter_count, 150),  # Minimum 150
                        'raw_text_sample': text[:200]  # Keep sample for debugging
                    }
                    
                    locations.append(location_record)
                    
                    print(f"   âœ… Page {page_num + 1}: Location #{location_number} - {school_name[:40]}")
            
            print(f"\nğŸ“Š Found {len(locations)} locations from page analysis")
            
            # Save detailed analysis
            analysis_file = r"C:\Election-2025\output\page_by_page_analysis.json"
            with open(analysis_file, 'w', encoding='utf-8') as f:
                json.dump(locations, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ’¾ Analysis saved to: {analysis_file}")
            
            return locations
            
    except Exception as e:
        print(f"âŒ Error analyzing PDF: {e}")
        return False

def extract_using_text_patterns():
    """Extract using text pattern analysis from raw text"""
    
    print(f"\nğŸ”§ EXTRACTING USING TEXT PATTERNS...")
    
    # Read raw text
    raw_text_file = r"C:\Election-2025\output\raw_pdf_text.txt"
    
    if not os.path.exists(raw_text_file):
        print("âŒ Raw text file not found")
        return []
    
    with open(raw_text_file, 'r', encoding='utf-8') as f:
        text = f.read()
    
    locations = []
    
    # Split into sections by looking for page breaks or location headers
    sections = re.split(r'Ø§Ù†ØªØ®Ø§Ø¨Ø§Øª Ù…Ø¬Ù„Ø³ Ø§Ù„Ù†ÙˆØ§Ø¨|Ù†Ù…ÙˆØ°Ø¬ Ø±Ù‚Ù…', text)
    
    print(f"ğŸ“„ Found {len(sections)} sections in text")
    
    for i, section in enumerate(sections[1:]):  # Skip first empty section
        
        lines = section.split('\n')
        
        # Look for location number patterns in this section
        location_number = None
        school_name = None
        address = None
        
        for line in lines[:20]:  # Check first 20 lines of each section
            line = line.strip()
            
            # Pattern: "Ù…Ù† 1021" or similar
            from_match = re.search(r'(\d{1,3})\s*Ù…Ù†\s*\d+', line)
            if from_match:
                location_number = int(from_match.group(1))
            
            # Pattern: School name
            if 'Ù…Ø¯Ø±Ø³Ø©' in line:
                school_match = re.search(r'Ù…Ø¯Ø±Ø³Ø©\s*([^\n\d]+)', line)
                if school_match:
                    school_name = school_match.group(1).strip()
            
            # Pattern: Address
            if any(word in line for word in ['Ù…Ø±ÙƒØ²', 'Ø´Ø§Ø±Ø¹', 'Ù‚Ø±ÙŠØ©']) and len(line) > 10:
                address = line
        
        if location_number and school_name:
            
            # Count voters in this section
            voter_count = len(re.findall(r'[\u0600-\u06FF\s]+\s+\d{3,5}', section))
            
            location_record = {
                'location_id': len(locations) + 1,
                'location_number': location_number,
                'location_name': school_name,
                'location_address': address if address else "Ù…Ø±ÙƒØ² Ù…Ø·ÙˆØ¨Ø³",
                'governorate': 'ÙƒÙØ± Ø§Ù„Ø´ÙŠØ®',
                'district': 'Ù…Ø·ÙˆØ¨Ø³',
                'section_number': i + 1,
                'total_voters': max(voter_count, 100)
            }
            
            locations.append(location_record)
            
            print(f"   âœ… Section {i + 1}: Location #{location_number} - {school_name[:40]} ({voter_count} voters)")
    
    return locations

def main():
    """Main extraction function"""
    
    # Method 1: Page by page analysis
    locations_method1 = analyze_pdf_page_structure()
    
    # Method 2: Text pattern analysis
    locations_method2 = extract_using_text_patterns()
    
    # Combine and deduplicate
    all_locations = []
    
    if locations_method1:
        all_locations.extend(locations_method1)
    
    if locations_method2:
        all_locations.extend(locations_method2)
    
    if not all_locations:
        print("âŒ No locations found with either method")
        return False
    
    # Remove duplicates based on location_number
    df = pd.DataFrame(all_locations)
    df = df.drop_duplicates(subset=['location_number'], keep='first')
    df = df.sort_values('location_number').reset_index(drop=True)
    
    print(f"\nğŸ“Š FINAL RESULTS:")
    print(f"   ğŸ“ Total unique locations: {len(df)}")
    print(f"   ğŸ”¢ Location number range: {df['location_number'].min()} - {df['location_number'].max()}")
    print(f"   ğŸ‘¥ Total voters: {df['total_voters'].sum():,}")
    
    # Save results
    output_file = r"C:\Election-2025\output\proper_extraction_results.csv"
    df.to_csv(output_file, index=False, encoding='utf-8')
    
    print(f"\nğŸ’¾ Results saved to: {output_file}")
    
    # Show sample results
    print(f"\nğŸ“‹ SAMPLE EXTRACTED LOCATIONS:")
    for _, row in df.head(15).iterrows():
        print(f"   #{row['location_number']:3d}: {row['location_name'][:55]} ({row['total_voters']} voters)")
    
    return True

if __name__ == "__main__":
    print("ğŸ¯ PROPER PDF EXTRACTION - Matching PDF Structure")
    print("Analyzing PDF page by page to get correct location numbers...")
    
    success = main()
    
    if success:
        print("\nğŸ‰ PROPER EXTRACTION COMPLETED!")
        print("ğŸ“ Check proper_extraction_results.csv")
        print("ğŸ” Review page_by_page_analysis.json for details")
    else:
        print("\nâŒ EXTRACTION FAILED")