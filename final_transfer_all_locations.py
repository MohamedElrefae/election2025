#!/usr/bin/env python3
"""
Egyptian Election Data - Final Transfer with All Locations
Transfers all 29 properly extracted locations and their voters to Supabase
"""

import pandas as pd
import json
import os
from supabase import create_client, Client
from datetime import datetime
import time
import numpy as np

def load_config():
    """Load Supabase configuration"""
    try:
        # Try to load from environment variables first
        import os
        url = os.getenv('SUPABASE_URL')
        key = os.getenv('SUPABASE_ANON_KEY')
        
        if url and key:
            return url, key
            
        # If not in environment, try to read from .env file
        env_file = '.env'
        if os.path.exists(env_file):
            with open(env_file, 'r') as f:
                lines = f.readlines()
                for line in lines:
                    if line.startswith('SUPABASE_URL='):
                        url = line.split('=', 1)[1].strip()
                    elif line.startswith('SUPABASE_ANON_KEY='):
                        key = line.split('=', 1)[1].strip()
        
        if not url or not key:
            print("âŒ Supabase configuration not found!")
            print("Please set SUPABASE_URL and SUPABASE_ANON_KEY environment variables")
            return None, None
            
        return url, key
        
    except Exception as e:
        print(f"âŒ Error loading configuration: {e}")
        return None, None

def clean_data_for_json(df):
    """Clean DataFrame to be JSON compliant"""
    df_clean = df.copy()
    
    # Replace NaN values with None (which becomes null in JSON)
    df_clean = df_clean.where(pd.notnull(df_clean), None)
    
    # Convert numpy types to Python native types
    for col in df_clean.columns:
        if df_clean[col].dtype == 'int64':
            df_clean[col] = df_clean[col].astype(int)
        elif df_clean[col].dtype == 'float64':
            # Convert float columns, handling NaN
            df_clean[col] = df_clean[col].apply(lambda x: int(x) if pd.notnull(x) and x != 0 else None)
    
    return df_clean

def clear_existing_data(supabase: Client):
    """Clear existing data from Supabase tables"""
    print("ğŸ§¹ Clearing existing data from Supabase...")
    
    try:
        # Clear voters first (due to foreign key constraint)
        print("   ğŸ—‘ï¸ Clearing voters table...")
        result = supabase.table('voters').delete().neq('id', 0).execute()
        print(f"   âœ… Cleared voters table")
        
        # Clear locations
        print("   ğŸ—‘ï¸ Clearing locations table...")
        result = supabase.table('locations').delete().neq('location_id', 0).execute()
        print(f"   âœ… Cleared locations table")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Error clearing data: {e}")
        return False

def transfer_all_locations():
    """Transfer all properly extracted locations and their voters to Supabase"""
    
    print("=" * 60)
    print("ğŸš€ Egyptian Election Data - Final Transfer (All 29 Locations)")
    print("=" * 60)
    
    # Load configuration
    url, key = load_config()
    if not url or not key:
        return False
    
    # Initialize Supabase client
    print("ğŸ”— Connecting to Supabase...")
    try:
        supabase: Client = create_client(url, key)
        print("âœ… Connected to Supabase successfully!")
    except Exception as e:
        print(f"âŒ Failed to connect to Supabase: {e}")
        return False
    
    # Clear existing data
    if not clear_existing_data(supabase):
        return False
    
    # Load properly extracted locations data
    locations_file = r"C:\Election-2025\output\locations_properly_extracted.csv"
    print(f"ğŸ“– Loading properly extracted locations from: {locations_file}")
    
    try:
        locations_df = pd.read_csv(locations_file)
        print(f"ğŸ“ Loaded {len(locations_df)} unique locations")
        
        # Clean data for JSON compliance
        print("ğŸ§¹ Cleaning data for JSON compliance...")
        locations_df_clean = clean_data_for_json(locations_df)
        
        # Show the locations we're transferring
        print(f"\nğŸ“‹ All {len(locations_df_clean)} locations to transfer:")
        for _, row in locations_df_clean.iterrows():
            loc_num = row['location_number']
            loc_name = row['location_name'][:50]
            voters = row['total_voters']
            print(f"   {loc_num:3d}: {loc_name:<50} ({voters} voters)")
            
    except Exception as e:
        print(f"âŒ Error loading locations: {e}")
        return False
    
    # Transfer locations
    print(f"\nğŸ“¤ Transferring {len(locations_df_clean)} locations to Supabase...")
    try:
        locations_data = locations_df_clean.to_dict('records')
        result = supabase.table('locations').insert(locations_data).execute()
        print(f"âœ… Successfully transferred {len(locations_data)} locations")
        
    except Exception as e:
        print(f"âŒ Error transferring locations: {e}")
        print(f"   Error details: {str(e)}")
        return False
    
    # Load voter data and filter for our locations
    voters_file = r"C:\Election-2025\output\voter_data_full.json"
    print(f"\nğŸ“– Loading voter data from: {voters_file}")
    
    try:
        with open(voters_file, 'r', encoding='utf-8') as f:
            voter_data_dict = json.load(f)
        
        # Extract the voters list from the dictionary
        if 'voters' in voter_data_dict:
            all_voters_data = voter_data_dict['voters']
        else:
            print("âŒ No 'voters' key found in voter data file")
            return False
        
        print(f"ğŸ‘¥ Loaded {len(all_voters_data)} total voters from file")
        
        # Get the location IDs we want to keep (all 29 locations)
        valid_location_ids = set(locations_df_clean['location_id'].tolist())
        print(f"ğŸ” Filtering voters for {len(valid_location_ids)} location IDs")
        
        # Filter voters to only include those from our locations
        filtered_voters = []
        for voter in all_voters_data:
            if isinstance(voter, dict) and voter.get('location_id') in valid_location_ids:
                filtered_voters.append(voter)
        
        print(f"âœ… Filtered to {len(filtered_voters)} voters from all locations")
        
        if len(filtered_voters) == 0:
            print("âš ï¸ No voters found for the locations!")
            print("Let me check the voter-location mapping...")
            
            # Show sample voter data
            if len(all_voters_data) > 0:
                sample_voter = all_voters_data[0]
                print(f"Sample voter: {sample_voter}")
                
                if isinstance(sample_voter, dict) and 'location_id' in sample_voter:
                    print(f"Sample location_id: {sample_voter['location_id']}")
            
            # Show all unique location_ids in voter data
            unique_location_ids = set()
            for voter in all_voters_data:
                if isinstance(voter, dict) and 'location_id' in voter:
                    unique_location_ids.add(voter['location_id'])
            
            print(f"Location IDs in voter data: {sorted(list(unique_location_ids))[:20]}...")
            print(f"Location IDs we want: {sorted(list(valid_location_ids))[:20]}...")
            
            return False
            
    except Exception as e:
        print(f"âŒ Error loading voter data: {e}")
        return False
    
    # Transfer voters in batches
    print(f"\nğŸ“¤ Transferring {len(filtered_voters)} voters to Supabase...")
    batch_size = 1000
    total_batches = (len(filtered_voters) + batch_size - 1) // batch_size
    
    try:
        for i in range(0, len(filtered_voters), batch_size):
            batch = filtered_voters[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            
            print(f"   ğŸ“¤ Batch {batch_num}/{total_batches}: {len(batch)} voters...")
            
            result = supabase.table('voters').insert(batch).execute()
            
            print(f"   âœ… Batch {batch_num} completed")
            time.sleep(0.1)  # Small delay to avoid rate limiting
        
        print(f"âœ… Successfully transferred all {len(filtered_voters)} voters")
        
    except Exception as e:
        print(f"âŒ Error transferring voters: {e}")
        return False
    
    # Verify the transfer
    print("\nğŸ” Verifying transfer...")
    try:
        # Count locations
        locations_result = supabase.table('locations').select('location_id').execute()
        locations_count = len(locations_result.data)
        
        # Count voters
        voters_result = supabase.table('voters').select('id').execute()
        voters_count = len(voters_result.data)
        
        print(f"âœ… Verification complete:")
        print(f"   ğŸ“ Locations in database: {locations_count}")
        print(f"   ğŸ‘¥ Voters in database: {voters_count}")
        
        # Show sample data
        if locations_count > 0:
            sample_location = supabase.table('locations').select('*').limit(1).execute()
            if sample_location.data:
                loc = sample_location.data[0]
                print(f"   ğŸ“ Sample location: {loc['location_name']}")
        
        if voters_count > 0:
            sample_voter = supabase.table('voters').select('*').limit(1).execute()
            if sample_voter.data:
                voter = sample_voter.data[0]
                print(f"   ğŸ‘¤ Sample voter: {voter['full_name']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error verifying transfer: {e}")
        return False

def show_final_summary():
    """Show final summary of the transfer"""
    print("\n" + "=" * 60)
    print("ğŸ‰ COMPLETE TRANSFER SUCCESS!")
    print("=" * 60)
    print("âœ… Your complete Egyptian election data is now in Supabase!")
    print("")
    print("ğŸ“Š What was transferred:")
    print("   ğŸ“ 29 unique polling locations with proper column separation")
    print("   ğŸ”¢ Location numbers (1-1007) in separate column")
    print("   ğŸ« Location names in separate column")
    print("   ğŸ“ Location addresses in separate column")
    print("   ğŸ›ï¸ District (Ù…Ø·ÙˆØ¨Ø³) in separate column")
    print("   ğŸ‘¥ All voters from those locations")
    print("   ğŸ§¹ Clean, properly structured data")
    print("")
    print("ğŸ« All 29 locations include:")
    locations = [
        "Ù…Ø·ÙˆØ¨Ø³ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø¨Ù†ÙŠÙ†", "Ø§Ù„Ø´Ù‡ÙŠØ¯ Ù†Ø¹Ù…Ø§Ù† Ø§Ù„Ø´Ù†Ø¯ÙˆÙŠÙ„Ù‰ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ù†Ø¬ÙŠÙ‡ Ø³Ù„Ù… Ø§Ù„Ø±Ø³Ù…ÙŠØ© Ù„Ù„ØºØ§Øª",
        "Ø¹Ù…Ø±Ùˆ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©", "Ø§Ù„Ø³Ø¹Ø§Ø¯Ù‡ Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰", "Ø§Ù„Ù‚Ù†Ù‰ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©",
        "Ø§Ù„Ù…Ù†Ø§Ø± Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„ØºÙ†Ø§ÙŠÙ… Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰", "Ø§Ù„Ø´Ù‡ÙŠØ¯/ Ø±Ø¶Ø§ ØµØ¨Ø±Ù‰ Ù…Ø­Ù…Ø¯ ÙØ±Ø§Ø¬ Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰",
        "Ø§Ù„Ø¯ÙˆØ§ÙŠØ¯Ø© Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰", "Ø³Ø¹Ø¯ Ø²ØºÙ„ÙˆÙ„ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ù…Ù†ÙŠØ© Ø§Ù„Ù…Ø±Ø´Ø¯ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©",
        "ÙØªØ­ Ø§ Ø¨Ø±ÙƒØ§Øª Ø§Ù„Ø¹Ø¯Ø§Ø¯ÙŠØ© Ø¨Ù†Ø§Øª", "Ø§Ù„Ø´Ù‡ÙŠØ¯ Ø§Ù„Ø¨Ø·Ù„ Ø¹Ù„Ù‰ Ù…Ø­Ù…Ø¯ ÙÙ‡Ù…Ù‰ ÙÙ„ÙŠÙÙ„ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©",
        "Ù…Ø¹Ø¯ÙŠØ© Ù…Ù‡Ø¯Ù‰ ØªØ¹Ù„ÙŠÙ… Ø§Ø³Ø§Ø³Ù‰", "Ø¹Ø¨Ø¯Ø§Ù„Ø­Ù…ÙŠØ¯ Ø´Ù„Ø¨Ù‰ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø§Ù„Ø®Ù„ÙŠØ¬ Ø§Ù„Ø¹Ø¯Ø§Ø¯ÙŠØ© Ø¨Ù†Ø§Øª",
        "Ø¬Ø²ÙŠØ±Ø© Ø§Ù„ÙØ±Ø³ Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰", "Ø§Ù„ÙŠØ³Ø±Ù‰ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ø·Ù„Ù…Ø¨Ø§Øª Ø²ØºÙ„ÙˆÙ„ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©",
        "Ø¹Ø±Ø¨ Ø§Ù„Ù…Ø­Ø¶Ø± Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰", "Ø§Ù„Ø¬Ø²ÙŠØ±Ø© Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©",
        "Ø§Ù„Ø¬Ø²ÙŠØ±Ø© Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©", "Ø§Ù„Ø´Ù‡ÙŠØ¯ Ø¹Ø¨Ø¯Ø§Ù„Ù†Ø¨Ù‰ Ù†ØµØ§Ø± Ø§Ù„Ø¹Ø¯Ø§Ø¯ÙŠØ© Ø¨Ù†Ø§Øª",
        "Ø§Ù„Ø¨ØµØ±Ø§Ø· Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ©", "Ù…Ø·ÙˆØ¨Ø³ Ø§Ù„Ø¨ØªØ¯Ø§Ø¦ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©", "Ø§Ù„Ù†Ø¬Ø§Ø±ÙŠÙ† Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰",
        "Ù…Ø·ÙˆØ¨Ø³ Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© Ø¨Ù†Ø§Øª", "Ø¹Ø²Ø¨Ø© Ø§Ù„Ø´Ø§Ø¹Ø± Ù„Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø³Ø§Ø³Ù‰"
    ]
    for i, loc in enumerate(locations, 1):
        print(f"   {i:2d}. {loc}")
    print("")
    print("ğŸ”— Next steps:")
    print("   1. Check your Supabase dashboard")
    print("   2. Query your data with proper column structure")
    print("   3. Build applications with complete dataset")
    print("=" * 60)

if __name__ == "__main__":
    success = transfer_all_locations()
    if success:
        show_final_summary()
    else:
        print("\nâŒ Transfer failed! Check the error messages above.")